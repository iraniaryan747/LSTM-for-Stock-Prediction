{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
      "     ---------------------------------------- 0.0/143.0 kB ? eta -:--:--\n",
      "     ----------------------------------- -- 133.1/143.0 kB 2.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 143.0/143.0 kB 1.7 MB/s eta 0:00:00\n",
      "Collecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.4.1-py3-none-any.whl (36 kB)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1282 sha256=abe4f2c3641e204a73100c9da0297e231b688b4f30e9558ff1eff937a5e0dccd\n",
      "  Stored in directory: c:\\users\\irani\\appdata\\local\\pip\\cache\\wheels\\75\\78\\21\\68b124549c9bdc94f822c02fb9aa3578a669843f9767776bca\n",
      "Successfully built bs4\n",
      "Installing collected packages: soupsieve, beautifulsoup4, bs4\n",
      "Successfully installed beautifulsoup4-4.12.2 bs4-0.0.1 soupsieve-2.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: C:\\Users\\Irani\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yfinance\n",
      "  Downloading yfinance-0.2.18-py2.py3-none-any.whl (60 kB)\n",
      "     ---------------------------------------- 0.0/60.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 60.3/60.3 kB 1.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\irani\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from yfinance) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\irani\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from yfinance) (1.23.5)\n",
      "Collecting cryptography>=3.3.2\n",
      "  Downloading cryptography-40.0.2-cp36-abi3-win_amd64.whl (2.6 MB)\n",
      "     ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.2/2.6 MB 5.1 MB/s eta 0:00:01\n",
      "     ----- ---------------------------------- 0.4/2.6 MB 3.8 MB/s eta 0:00:01\n",
      "     ------- -------------------------------- 0.5/2.6 MB 4.0 MB/s eta 0:00:01\n",
      "     ---------- ----------------------------- 0.7/2.6 MB 3.6 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 0.9/2.6 MB 3.6 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 1.0/2.6 MB 3.7 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 1.2/2.6 MB 3.8 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 1.4/2.6 MB 3.7 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 1.6/2.6 MB 3.7 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 1.7/2.6 MB 3.6 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 1.9/2.6 MB 3.6 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 2.1/2.6 MB 3.8 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 2.2/2.6 MB 3.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 2.4/2.6 MB 3.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.6/2.6 MB 3.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.6/2.6 MB 3.4 MB/s eta 0:00:00\n",
      "Collecting frozendict>=2.3.4\n",
      "  Downloading frozendict-2.3.8-cp38-cp38-win_amd64.whl (35 kB)\n",
      "Collecting appdirs>=1.4.4\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: requests>=2.26 in c:\\users\\irani\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from yfinance) (2.28.2)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\users\\irani\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from yfinance) (2022.7.1)\n",
      "Collecting html5lib>=1.1\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "     ---------------------------------------- 0.0/112.2 kB ? eta -:--:--\n",
      "     -------------------------------------- 112.2/112.2 kB 3.3 MB/s eta 0:00:00\n",
      "Collecting multitasking>=0.0.7\n",
      "  Using cached multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n",
      "Collecting lxml>=4.9.1\n",
      "  Downloading lxml-4.9.2-cp38-cp38-win_amd64.whl (3.9 MB)\n",
      "     ---------------------------------------- 0.0/3.9 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.2/3.9 MB 3.9 MB/s eta 0:00:01\n",
      "     --- ------------------------------------ 0.4/3.9 MB 3.8 MB/s eta 0:00:01\n",
      "     ----- ---------------------------------- 0.6/3.9 MB 4.0 MB/s eta 0:00:01\n",
      "     -------- ------------------------------- 0.8/3.9 MB 4.0 MB/s eta 0:00:01\n",
      "     ---------- ----------------------------- 1.0/3.9 MB 3.8 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 1.2/3.9 MB 3.8 MB/s eta 0:00:01\n",
      "     -------------- ------------------------- 1.4/3.9 MB 3.8 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 1.6/3.9 MB 3.7 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 1.8/3.9 MB 3.8 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 2.0/3.9 MB 3.8 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 2.1/3.9 MB 3.8 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 2.3/3.9 MB 3.7 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 2.5/3.9 MB 3.7 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 2.6/3.9 MB 3.7 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 2.8/3.9 MB 3.7 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 2.9/3.9 MB 3.7 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 3.1/3.9 MB 3.7 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 3.4/3.9 MB 3.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 3.6/3.9 MB 3.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 3.7/3.9 MB 3.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  3.9/3.9 MB 3.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  3.9/3.9 MB 3.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.9/3.9 MB 3.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\irani\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from yfinance) (1.5.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\irani\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.4.1)\n",
      "Collecting cffi>=1.12\n",
      "  Downloading cffi-1.15.1-cp38-cp38-win_amd64.whl (178 kB)\n",
      "     ---------------------------------------- 0.0/178.8 kB ? eta -:--:--\n",
      "     ------------------------------------ - 174.1/178.8 kB 5.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- 178.8/178.8 kB 3.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\irani\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
      "Collecting webencodings\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\irani\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\irani\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from requests>=2.26->yfinance) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\irani\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from requests>=2.26->yfinance) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\irani\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from requests>=2.26->yfinance) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\irani\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from requests>=2.26->yfinance) (1.26.14)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "     ---------------------------------------- 0.0/118.7 kB ? eta -:--:--\n",
      "     -------------------------------------- 118.7/118.7 kB 3.4 MB/s eta 0:00:00\n",
      "Installing collected packages: webencodings, multitasking, appdirs, pycparser, lxml, html5lib, frozendict, cffi, cryptography, yfinance\n",
      "Successfully installed appdirs-1.4.4 cffi-1.15.1 cryptography-40.0.2 frozendict-2.3.8 html5lib-1.1 lxml-4.9.2 multitasking-0.0.11 pycparser-2.21 webencodings-0.5.1 yfinance-0.2.18\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: C:\\Users\\Irani\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/10\n",
      "47/47 [==============================] - 6s 10ms/step - loss: 0.0309\n",
      "Epoch 2/10\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.0023\n",
      "Epoch 3/10\n",
      "47/47 [==============================] - 1s 20ms/step - loss: 0.0018\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0018\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 1s 16ms/step - loss: 0.0017\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.0018\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 1s 18ms/step - loss: 0.0017\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 1s 21ms/step - loss: 0.0016\n",
      "Epoch 9/10\n",
      "47/47 [==============================] - 1s 16ms/step - loss: 0.0016\n",
      "Epoch 10/10\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.0015\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Predicted stock price for the next day: 65.95639\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import yfinance as yf\n",
    "\n",
    "# Retrieve stock data from Yahoo Finance API\n",
    "stock_data = yf.download(\"IDFCFIRSTB.NS\", start=\"2010-01-01\", end=\"2023-05-22\")  # Replace \"HDFCBANK.NS\" with the HDFC Bank stock symbol\n",
    "\n",
    "# Preprocess the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(stock_data['Close'].values.reshape(-1, 1))\n",
    "\n",
    "# Web scrape news articles from moneycontrol.com\n",
    "url = 'https://www.moneycontrol.com/news/tags/hdfc-bank.html'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "articles = soup.find_all('div', class_='common_news_main')\n",
    "\n",
    "# Extract relevant information from scraped articles\n",
    "news_data = []\n",
    "for article in articles:\n",
    "    title = article.find('a').text.strip()\n",
    "    date = article.find('span', class_='mr10').text.strip()\n",
    "    content = article.find('p').text.strip()\n",
    "    news_data.append({'Title': title, 'Date': date, 'Content': content})\n",
    "\n",
    "# Convert news data to a DataFrame\n",
    "news_df = pd.DataFrame(news_data)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_size = int(len(scaled_data) * 0.8)  # 80% for training, 20% for testing\n",
    "train_data = scaled_data[:train_size]\n",
    "test_data = scaled_data[train_size:]\n",
    "\n",
    "# Convert the data into sequences\n",
    "def create_sequences(data, seq_length):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i + seq_length])\n",
    "        y.append(data[i + seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "seq_length = 10  # Length of the input sequence\n",
    "X_train, y_train = create_sequences(train_data, seq_length)\n",
    "X_test, y_test = create_sequences(test_data, seq_length)\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(seq_length, 1)))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(units=1))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Make predictions for the next day\n",
    "last_sequence = X_test[-1]  # Take the last sequence from the testing set\n",
    "next_day = model.predict(last_sequence.reshape(1, seq_length, 1))  # Predict the next day's price\n",
    "\n",
    "# Inverse scale the prediction\n",
    "next_day = scaler.inverse_transform(next_day)\n",
    "\n",
    "print(\"Predicted stock price for the next day:\", next_day[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- IDFCFIRSTB.NS: ValueError('unconverted data remains:  14:00:00')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by MinMaxScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39m# Preprocess the data\u001b[39;00m\n\u001b[0;32m     19\u001b[0m scaler \u001b[39m=\u001b[39m MinMaxScaler(feature_range\u001b[39m=\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[1;32m---> 20\u001b[0m scaled_data \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39;49mfit_transform(stock_data[\u001b[39m'\u001b[39;49m\u001b[39mClose\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mvalues\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m))\n\u001b[0;32m     22\u001b[0m \u001b[39m# Web scrape news articles from moneycontrol.com\u001b[39;00m\n\u001b[0;32m     23\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://www.moneycontrol.com/news/tags/\u001b[39m\u001b[39m{\u001b[39;00mstock_symbol\u001b[39m.\u001b[39mlower()\u001b[39m}\u001b[39;00m\u001b[39m.html\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\utils\\_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 142\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    143\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    144\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    145\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    147\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    148\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\base.py:859\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    855\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    858\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[0;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    861\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\preprocessing\\_data.py:427\u001b[0m, in \u001b[0;36mMinMaxScaler.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[39m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> 427\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpartial_fit(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\preprocessing\\_data.py:466\u001b[0m, in \u001b[0;36mMinMaxScaler.partial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    461\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMinMaxScaler does not support sparse input. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    462\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConsider using MaxAbsScaler instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    463\u001b[0m     )\n\u001b[0;32m    465\u001b[0m first_pass \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mn_samples_seen_\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 466\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    467\u001b[0m     X,\n\u001b[0;32m    468\u001b[0m     reset\u001b[39m=\u001b[39;49mfirst_pass,\n\u001b[0;32m    469\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[0;32m    470\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    471\u001b[0m )\n\u001b[0;32m    473\u001b[0m data_min \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnanmin(X, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m    474\u001b[0m data_max \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnanmax(X, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\base.py:546\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    545\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 546\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[0;32m    547\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    548\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\utils\\validation.py:931\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n\u001b[0;32m    930\u001b[0m     \u001b[39mif\u001b[39;00m n_samples \u001b[39m<\u001b[39m ensure_min_samples:\n\u001b[1;32m--> 931\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    932\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m sample(s) (shape=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) while a\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    933\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m minimum of \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m is required\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    934\u001b[0m             \u001b[39m%\u001b[39m (n_samples, array\u001b[39m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m    935\u001b[0m         )\n\u001b[0;32m    937\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_features \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    938\u001b[0m     n_features \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by MinMaxScaler."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/10\n",
      "82/82 [==============================] - 7s 34ms/step - loss: 0.0086\n",
      "Epoch 2/10\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 3.1004e-04\n",
      "Epoch 3/10\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 2.6561e-04\n",
      "Epoch 4/10\n",
      "82/82 [==============================] - 3s 36ms/step - loss: 2.6021e-04\n",
      "Epoch 5/10\n",
      "82/82 [==============================] - 3s 36ms/step - loss: 2.5858e-04\n",
      "Epoch 6/10\n",
      "82/82 [==============================] - 3s 37ms/step - loss: 2.4039e-04\n",
      "Epoch 7/10\n",
      "82/82 [==============================] - 3s 37ms/step - loss: 2.3620e-04\n",
      "Epoch 8/10\n",
      "82/82 [==============================] - 3s 38ms/step - loss: 2.5180e-04\n",
      "Epoch 9/10\n",
      "82/82 [==============================] - 3s 36ms/step - loss: 2.1424e-04\n",
      "Epoch 10/10\n",
      "82/82 [==============================] - 3s 38ms/step - loss: 1.8922e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Irani\\AppData\\Local\\Temp\\ipykernel_9848\\3136603989.py:72: FutureWarning: Passing method to DatetimeIndex.get_loc is deprecated and will raise in a future version. Use index.get_indexer([item], method=...) instead.\n",
      "  prediction_index = stock_data.index.get_loc(prediction_datetime, method='nearest')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 992ms/step\n",
      "Predicted stock price for HDFCBANK.NS at 2023-05-24 10:00:00 : 1578.56\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "\n",
    "# Prompt user for stock symbol and prediction time\n",
    "stock_symbol = input(\"Enter the stock symbol (e.g., AAPL, HDFCBANK.NS): \")\n",
    "prediction_date = input(\"Enter the prediction date (ddmmyyyy): \")\n",
    "prediction_time = input(\"Enter the prediction time (hh:mm AM/PM): \")\n",
    "\n",
    "# Convert prediction date and time to datetime object\n",
    "prediction_datetime = datetime.strptime(prediction_date + prediction_time, \"%d%m%Y%I:%M %p\")\n",
    "\n",
    "# Retrieve stock data from Yahoo Finance API\n",
    "stock_data = yf.download(stock_symbol, start=\"2010-01-01\", end=prediction_datetime)\n",
    "\n",
    "# Preprocess the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(stock_data['Close'].values.reshape(-1, 1))\n",
    "\n",
    "# Web scrape news articles from moneycontrol.com\n",
    "url = f\"https://www.moneycontrol.com/news/tags/{stock_symbol.lower()}.html\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "articles = soup.find_all('div', class_='common_news_main')\n",
    "\n",
    "# Extract relevant information from scraped articles\n",
    "news_data = []\n",
    "for article in articles:\n",
    "    title = article.find('a').text.strip()\n",
    "    date = article.find('span', class_='mr10').text.strip()\n",
    "    content = article.find('p').text.strip()\n",
    "    news_data.append({'Title': title, 'Date': date, 'Content': content})\n",
    "\n",
    "# Convert news data to a DataFrame\n",
    "news_df = pd.DataFrame(news_data)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_size = int(len(scaled_data) * 0.8)  # 80% for training, 20% for testing\n",
    "train_data = scaled_data[:train_size]\n",
    "test_data = scaled_data[train_size:]\n",
    "\n",
    "# Convert the data into sequences\n",
    "def create_sequences(data, seq_length):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i + seq_length])\n",
    "        y.append(data[i + seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "seq_length = 50  # Length of the input sequence\n",
    "X_train, y_train = create_sequences(train_data, seq_length)\n",
    "X_test, y_test = create_sequences(test_data, seq_length)\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(seq_length, 1)))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(units=1))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Find the corresponding index in the stock data\n",
    "prediction_index = stock_data.index.get_loc(prediction_datetime, method='nearest')\n",
    "\n",
    "# Prepare the input data for prediction\n",
    "last_sequence = scaled_data[prediction_index - seq_length:prediction_index].reshape(1, seq_length, 1)\n",
    "\n",
    "# Make the prediction\n",
    "predicted_price = model.predict(last_sequence)\n",
    "predicted_price = scaler.inverse_transform(predicted_price)\n",
    "\n",
    "print(\"Predicted stock price for\", stock_symbol, \"at\", prediction_datetime, \":\", predicted_price[0, 0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "\n",
    "# Prompt user for stock symbols and prediction time\n",
    "stock_symbols = input(\"Enter the stock symbols (comma-separated, e.g., AAPL,GOOGL,HDFCBANK.NS): \")\n",
    "prediction_date = input(\"Enter the prediction date (ddmmyyyy): \")\n",
    "prediction_time = input(\"Enter the prediction time (hh:mm AM/PM): \")\n",
    "\n",
    "# Convert stock symbols to a list\n",
    "stock_symbols = [symbol.strip() for symbol in stock_symbols.split(\",\")]\n",
    "\n",
    "# Convert prediction date and time to datetime object\n",
    "prediction_datetime = datetime.strptime(prediction_date + prediction_time, \"%d%m%Y%I:%M %p\")\n",
    "\n",
    "# Retrieve stock data from Yahoo Finance API for each stock symbol\n",
    "stock_data = {}\n",
    "for symbol in stock_symbols:\n",
    "    stock_data[symbol] = yf.download(symbol, start=\"2010-01-01\", end=prediction_datetime)\n",
    "\n",
    "# Preprocess the data for each stock\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = {}\n",
    "for symbol, data in stock_data.items():\n",
    "    scaled_data[symbol] = scaler.fit_transform(data['Close'].values.reshape(-1, 1))\n",
    "\n",
    "# Split the data into training and testing sets for each stock\n",
    "train_data = {}\n",
    "test_data = {}\n",
    "for symbol, data in scaled_data.items():\n",
    "    train_size = int(len(data) * 0.8)  # 80% for training, 20% for testing\n",
    "    train_data[symbol] = data[:train_size]\n",
    "    test_data[symbol] = data[train_size:]\n",
    "\n",
    "# Convert the data into sequences for each stock\n",
    "seq_length = 50  # Length of the input sequence\n",
    "X_train = {}\n",
    "y_train = {}\n",
    "X_test = {}\n",
    "y_test = {}\n",
    "for symbol in stock_symbols:\n",
    "    X_train[symbol], y_train[symbol] = create_sequences(train_data[symbol], seq_length)\n",
    "    X_test[symbol], y_test[symbol] = create_sequences(test_data[symbol], seq_length)\n",
    "\n",
    "# Train and evaluate the LSTM model for each stock\n",
    "models = {}\n",
    "for symbol in stock_symbols:\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=False, input_shape=(seq_length, 1)))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.fit(X_train[symbol], y_train[symbol], epochs=10, batch_size=32)\n",
    "    models[symbol] = model\n",
    "\n",
    "# Predict the stock prices for each stock\n",
    "for symbol in stock_symbols:\n",
    "    last_sequence = X_test[symbol][-1]  # Get the last sequence from the test data\n",
    "    last_sequence = last_sequence.reshape(1, seq_length, 1)  # Reshape for prediction\n",
    "    predicted_price = models[symbol].predict(last_sequence)  # Predict the next stock price\n",
    "    predicted_price = scaler.inverse_transform(predicted_price)  # Scale back the predicted price\n",
    "    print(\"Stock Symbol:\", symbol)\n",
    "    print(\"Predicted Stock Price:\", predicted_price[0][0])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
